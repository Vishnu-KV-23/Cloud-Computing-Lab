from pyspark import SparkContext

# Initialize SparkContext

sc = SparkContext("local","palindrome")

# Load the input data

text_file = sc.textFile("path/to/your/textfile.txt")




#same for all programs in pyspark until now


#flaptmap- to flatten text
#to sep using space and all


#map-


# Function to check if a word is a palindrome
def is_palindrome(word):
    return word == word[::-1]

# Find palindromic words
palindromic_words = (text_file
                     .flatMap(lambda line: line.split())      # Split each line into words
                     .filter(is_palindrome)                   # Filter to keep only palindromic words
                     .distinct())                             # Remove duplicates

# Collect and print the results
for word in palindromic_words.collect():
    print(word)

# Stop the SparkContext
sc.stop()
